{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving Record Linkage (PPRL)\n",
    "\n",
    "Bloom filter-based privacy-preserving record linkage with differential privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 1: Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from BF import BF\n",
    "from PPRL import Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 2: Configure Parameters for Linkage\n\n**Modify these values to tune the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY THESE PARAMETERS TO TUNE LINKAGE ACCURACY:\n",
    "BF_length = 1000        # Bloom filter length (larger = more memory, less collisions)\n",
    "BF_num_hash = 10        # Number of hash functions (affects false positive rate)\n",
    "BF_q_gram = 2           # Q-gram size for tokenization\n",
    "min_sim_val = 0.8       # Similarity threshold for matching (0-1)\n",
    "link_attrs = [1,2,3,4]  # Attributes to use for linkage\n",
    "block_attrs = [2,4]     # Attributes to use for blocking\n",
    "ent_index = 0           # Entity ID column index\n",
    "epsilon = 7             # Privacy budget (lower = more privacy, less accuracy)\n",
    "\n",
    "link = Link(BF_length, BF_num_hash, BF_q_gram, min_sim_val, link_attrs, block_attrs, ent_index, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 3: Load Datasets\n\n**Modify dataset paths to test different data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY THESE PATHS TO USE DIFFERENT DATASETS:\n",
    "dataset1_path = '../csv_files/Alice_numrec_100_corr_50.csv'\n",
    "dataset2_path = '../csv_files/Bob_numrec_100_corr_50.csv'\n",
    "\n",
    "db1 = link.read_database(dataset1_path)\n",
    "db2 = link.read_database(dataset2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 4: PPRL Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "blk_ind1 = link.build_BI(db1)\n",
    "blk_ind2 = link.build_BI(db2)\n",
    "\n",
    "bf_dict1, all_val_set1 = link.data_encode(db1)\n",
    "bf_dict2, all_val_set2 = link.data_encode(db2)\n",
    "\n",
    "all_val_set = all_val_set1 + all_val_set2\n",
    "total_all_val_set = set(all_val_set)\n",
    "num_total_all_val_set = len(total_all_val_set)\n",
    "fpr = (1 - math.e**((-1*BF_num_hash*num_total_all_val_set)/BF_length))**BF_num_hash\n",
    "\n",
    "bf_dict1_dp = link.dp_bloom_filters(bf_dict1)\n",
    "bf_dict2_dp = link.dp_bloom_filters(bf_dict2)\n",
    "\n",
    "matches = link.match(blk_ind1, blk_ind2, bf_dict1_dp, bf_dict2_dp)\n",
    "\n",
    "end_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 5: Evaluate PPRL Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== PPRL with Differential Privacy ===')\n",
    "prec, rec, f1 = link.evaluate(matches, db1, db2)\n",
    "print(f'False Positive Rate: {fpr:.4f}')\n",
    "print(f'Privacy Budget (\u03b5): {epsilon}')\n",
    "print(f'Runtime: {end_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 6: Baseline Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_npp = link.match_npp(blk_ind1, blk_ind2, db1, db2)\n",
    "print('\\n=== Non-Privacy-Preserving Baseline ===')\n",
    "prec_b1, rec_b1, f1_b1 = link.evaluate(matches_npp, db1, db2)\n",
    "\n",
    "matches_nodp = link.match(blk_ind1, blk_ind2, bf_dict1, bf_dict2)\n",
    "print('\\n=== PPRL without Differential Privacy ===')\n",
    "prec_b2, rec_b2, f1_b2 = link.evaluate(matches_nodp, db1, db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 7: Parameter Comparison Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parameter_variations(datasets, param_name, param_values, base_params):\n",
    "    results = []\n",
    "    \n",
    "    for dataset_name, (path1, path2) in datasets.items():\n",
    "        for param_val in param_values:\n",
    "            params = base_params.copy()\n",
    "            params[param_name] = param_val\n",
    "            \n",
    "            link_test = Link(params['BF_length'], params['BF_num_hash'], params['BF_q_gram'],\n",
    "                           params['min_sim_val'], params['link_attrs'], params['block_attrs'],\n",
    "                           params['ent_index'], params['epsilon'])\n",
    "            \n",
    "            db1_test = link_test.read_database(path1)\n",
    "            db2_test = link_test.read_database(path2)\n",
    "            \n",
    "            blk_ind1_test = link_test.build_BI(db1_test)\n",
    "            blk_ind2_test = link_test.build_BI(db2_test)\n",
    "            \n",
    "            bf_dict1_test, _ = link_test.data_encode(db1_test)\n",
    "            bf_dict2_test, _ = link_test.data_encode(db2_test)\n",
    "            \n",
    "            bf_dict1_dp_test = link_test.dp_bloom_filters(bf_dict1_test)\n",
    "            bf_dict2_dp_test = link_test.dp_bloom_filters(bf_dict2_test)\n",
    "            \n",
    "            matches_test = link_test.match(blk_ind1_test, blk_ind2_test, bf_dict1_dp_test, bf_dict2_dp_test)\n",
    "            prec_test, rec_test, f1_test = link_test.evaluate(matches_test, db1_test, db2_test)\n",
    "            \n",
    "            results.append({\n",
    "                'dataset': dataset_name,\n",
    "                'param_value': param_val,\n",
    "                'precision': prec_test,\n",
    "                'recall': rec_test,\n",
    "                'f1_score': f1_test\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "base_params = {\n",
    "    'BF_length': 1000,\n",
    "    'BF_num_hash': 10,\n",
    "    'BF_q_gram': 2,\n",
    "    'min_sim_val': 0.8,\n",
    "    'link_attrs': [1,2,3,4],\n",
    "    'block_attrs': [2,4],\n",
    "    'ent_index': 0,\n",
    "    'epsilon': 7\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    '100_corr_25': ('../csv_files/Alice_numrec_100_corr_25.csv', '../csv_files/Bob_numrec_100_corr_25.csv'),\n",
    "    '100_corr_50': ('../csv_files/Alice_numrec_100_corr_50.csv', '../csv_files/Bob_numrec_100_corr_50.csv'),\n",
    "    '500_corr_25': ('../csv_files/Alice_numrec_500_corr_25.csv', '../csv_files/Bob_numrec_500_corr_25.csv'),\n",
    "    '500_corr_50': ('../csv_files/Alice_numrec_500_corr_50.csv', '../csv_files/Bob_numrec_500_corr_50.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 8: Privacy Budget (Epsilon) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_values = [1, 3, 5, 7, 10, 15]\n",
    "epsilon_results = test_parameter_variations(datasets, 'epsilon', epsilon_values, base_params)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for dataset_name in datasets.keys():\n",
    "    data = epsilon_results[epsilon_results['dataset'] == dataset_name]\n",
    "    axes[0].plot(data['param_value'], data['precision'], marker='o', label=dataset_name)\n",
    "    axes[1].plot(data['param_value'], data['recall'], marker='o', label=dataset_name)\n",
    "    axes[2].plot(data['param_value'], data['f1_score'], marker='o', label=dataset_name)\n",
    "\n",
    "axes[0].set_xlabel('Privacy Budget (\u03b5)')\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title('Precision vs Privacy Budget')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Privacy Budget (\u03b5)')\n",
    "axes[1].set_ylabel('Recall')\n",
    "axes[1].set_title('Recall vs Privacy Budget')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].set_xlabel('Privacy Budget (\u03b5)')\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].set_title('F1 Score vs Privacy Budget')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pprl_epsilon_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nEpsilon Results Summary:')\n",
    "print(epsilon_results.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 9: Similarity Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_values = [0.6, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "threshold_results = test_parameter_variations(datasets, 'min_sim_val', threshold_values, base_params)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for dataset_name in datasets.keys():\n",
    "    data = threshold_results[threshold_results['dataset'] == dataset_name]\n",
    "    axes[0].plot(data['param_value'], data['precision'], marker='s', label=dataset_name)\n",
    "    axes[1].plot(data['param_value'], data['recall'], marker='s', label=dataset_name)\n",
    "    axes[2].plot(data['param_value'], data['f1_score'], marker='s', label=dataset_name)\n",
    "\n",
    "axes[0].set_xlabel('Similarity Threshold')\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title('Precision vs Similarity Threshold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Similarity Threshold')\n",
    "axes[1].set_ylabel('Recall')\n",
    "axes[1].set_title('Recall vs Similarity Threshold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].set_xlabel('Similarity Threshold')\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].set_title('F1 Score vs Similarity Threshold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pprl_threshold_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nThreshold Results Summary:')\n",
    "print(threshold_results.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 10: Bloom Filter Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_length_values = [500, 1000, 1500, 2000]\n",
    "bf_length_results = test_parameter_variations(datasets, 'BF_length', bf_length_values, base_params)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for dataset_name in datasets.keys():\n",
    "    data = bf_length_results[bf_length_results['dataset'] == dataset_name]\n",
    "    axes[0].plot(data['param_value'], data['precision'], marker='^', label=dataset_name)\n",
    "    axes[1].plot(data['param_value'], data['recall'], marker='^', label=dataset_name)\n",
    "    axes[2].plot(data['param_value'], data['f1_score'], marker='^', label=dataset_name)\n",
    "\n",
    "axes[0].set_xlabel('Bloom Filter Length')\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title('Precision vs BF Length')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Bloom Filter Length')\n",
    "axes[1].set_ylabel('Recall')\n",
    "axes[1].set_title('Recall vs BF Length')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].set_xlabel('Bloom Filter Length')\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].set_title('F1 Score vs BF Length')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pprl_bf_length_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nBF Length Results Summary:')\n",
    "print(bf_length_results.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 11: Number of Hash Functions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hash_values = [5, 10, 15, 20]\n",
    "num_hash_results = test_parameter_variations(datasets, 'BF_num_hash', num_hash_values, base_params)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for dataset_name in datasets.keys():\n",
    "    data = num_hash_results[num_hash_results['dataset'] == dataset_name]\n",
    "    axes[0].plot(data['param_value'], data['precision'], marker='d', label=dataset_name)\n",
    "    axes[1].plot(data['param_value'], data['recall'], marker='d', label=dataset_name)\n",
    "    axes[2].plot(data['param_value'], data['f1_score'], marker='d', label=dataset_name)\n",
    "\n",
    "axes[0].set_xlabel('Number of Hash Functions')\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title('Precision vs Number of Hashes')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Number of Hash Functions')\n",
    "axes[1].set_ylabel('Recall')\n",
    "axes[1].set_title('Recall vs Number of Hashes')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].set_xlabel('Number of Hash Functions')\n",
    "axes[2].set_ylabel('F1 Score')\n",
    "axes[2].set_title('F1 Score vs Number of Hashes')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pprl_num_hash_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nNumber of Hash Functions Results Summary:')\n",
    "print(num_hash_results.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE 12: Combined Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "for dataset_name in datasets.keys():\n",
    "    eps_data = epsilon_results[epsilon_results['dataset'] == dataset_name]\n",
    "    axes[0, 0].plot(eps_data['param_value'], eps_data['f1_score'], marker='o', label=dataset_name)\n",
    "    \n",
    "    th_data = threshold_results[threshold_results['dataset'] == dataset_name]\n",
    "    axes[0, 1].plot(th_data['param_value'], th_data['f1_score'], marker='s', label=dataset_name)\n",
    "    \n",
    "    bf_data = bf_length_results[bf_length_results['dataset'] == dataset_name]\n",
    "    axes[1, 0].plot(bf_data['param_value'], bf_data['f1_score'], marker='^', label=dataset_name)\n",
    "    \n",
    "    nh_data = num_hash_results[num_hash_results['dataset'] == dataset_name]\n",
    "    axes[1, 1].plot(nh_data['param_value'], nh_data['f1_score'], marker='d', label=dataset_name)\n",
    "\n",
    "axes[0, 0].set_title('F1 Score vs Privacy Budget (\u03b5)')\n",
    "axes[0, 0].set_xlabel('Privacy Budget (\u03b5)')\n",
    "axes[0, 0].set_ylabel('F1 Score')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].set_title('F1 Score vs Similarity Threshold')\n",
    "axes[0, 1].set_xlabel('Similarity Threshold')\n",
    "axes[0, 1].set_ylabel('F1 Score')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].set_title('F1 Score vs BF Length')\n",
    "axes[1, 0].set_xlabel('Bloom Filter Length')\n",
    "axes[1, 0].set_ylabel('F1 Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].set_title('F1 Score vs Number of Hashes')\n",
    "axes[1, 1].set_xlabel('Number of Hash Functions')\n",
    "axes[1, 1].set_ylabel('F1 Score')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pprl_combined_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}