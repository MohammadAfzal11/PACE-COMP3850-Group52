{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving Record Linkage using Bloom filters and Similarity threshold-based classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The problem we consider is a privacy-preserving record linkage with binary class output (match and non-match). Match refer to the pair of records corresponding to the same entity, while non-match refer to the status of record pairs corresponding to different entities. The code below aims to link records from two datasets (currently only supports two-database linkage) while preserving their privacy. We assume that we have a set of common personal identifying attributes, known as Quasi-Identifiers (QIDs), such as names and addresses, in both datasets to perform the linkage. Since these QIDs contain personal identifiable information, they are encoded into Bloom filters, which are then perturbed to add differential privacy noise to provide bit-level differential privacy. The matching of these QIDs (encoded into Bloom filters) is calculated using a similarity function, that returns a simialrity score in the range  [0,1]. A simple similarity threshold-based classifier is then used to classify the record pairs that have a simialrity above the given threshold as 'matches'. Two baselines are considered to evalaute and compare the performances: 1) non-privacy-preserving record linkage method (that matches and links records using their actual QIDs without encoding and/or perturbing them), and 2) Bloom filter-based privacy-preserving record linkage without differential privacy guarantees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "# lowercase, because pip installed 'bf', not 'BF'\n",
    "from BF import BF    \n",
    "\n",
    "# this is your local file 'PPRL.py'\n",
    "from PPRL import Link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of class Link with the following parameter values\n",
    "#Modify the values below to fine-tune the hyper-parameters\n",
    "#\n",
    "BF_length = 1000\n",
    "BF_num_hash = 10\n",
    "BF_q_gram = 2\n",
    "min_sim_val = 0.8\n",
    "link_attrs = [1,2,3,4]\n",
    "block_attrs = [2,4]\n",
    "ent_index = 0\n",
    "epsilon = 7\n",
    "\n",
    "link = Link(BF_length,BF_num_hash,BF_q_gram,min_sim_val,link_attrs,block_attrs,ent_index,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data file: ../csv_files/Alice_numrec_100_corr_50.csv\n",
      "Read 100 records\n"
     ]
    }
   ],
   "source": [
    "#Read the first dataset - provide the link for the first dataset\n",
    "db1 = link.read_database('../csv_files/Alice_numrec_100_corr_50.csv')\n",
    "#print(db1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data file: ../csv_files/Bob_numrec_100_corr_50.csv\n",
      "Read 100 records\n"
     ]
    }
   ],
   "source": [
    "#Read the second dataset - provide the link for the second dataset\n",
    "db2 = link.read_database('../csv_files/Bob_numrec_100_corr_50.csv')\n",
    "#print(db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Block Index for attributes: [2, 4]\n",
      "Generate 97 blocks\n",
      "Build Block Index for attributes: [2, 4]\n",
      "Generate 90 blocks\n"
     ]
    }
   ],
   "source": [
    "#Apply blocking on the two datasets\n",
    "blk_ind1 = link.build_BI(db1)\n",
    "blk_ind2 = link.build_BI(db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9346272479320712\n"
     ]
    }
   ],
   "source": [
    "#Encode records into Bloom filters\n",
    "bf_dict1, all_val_set1 = link.data_encode(db1)\n",
    "bf_dict2, all_val_set2 = link.data_encode(db2)\n",
    "\n",
    "#Calculate false positive rate of bloom filter encoding\n",
    "all_val_set = all_val_set1 + all_val_set2\n",
    "total_all_val_set = set(all_val_set)\n",
    "num_total_all_val_set = len(total_all_val_set)\n",
    "\n",
    "fpr = (1 - math.e**((-1*BF_num_hash*num_total_all_val_set)/BF_length))**BF_num_hash\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add bit-level differential privacy noise to Bloom filters\n",
    "pbf_dict1 = link.add_DP_noise(bf_dict1)\n",
    "pbf_dict2 = link.add_DP_noise(bf_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of common blocks: 51\n",
      "Number of matching pairs: 32\n"
     ]
    }
   ],
   "source": [
    "#Match and link Bloom filters from the two datasets\n",
    "matches = link.match(blk_ind1,blk_ind2,pbf_dict1,pbf_dict2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time in seconds: 0.10302209854125977\n"
     ]
    }
   ],
   "source": [
    "#Evaluate runtime\n",
    "end_time = time.time() - start_time\n",
    "print('Total time in seconds:', end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linkage quality of PPRL\n",
      "Precision:  1.0\n",
      "Recall:  0.64\n",
      "F1 score:  0.7804878048780487\n",
      "Probable Privacy guarantees: false positive rate of Bloom filters (larger better) -  0.9346272479320712\n",
      "Provable Privacy guarantees: Privacy budget (smaller better) -  7\n"
     ]
    }
   ],
   "source": [
    "#Evaluate linkage quality\n",
    "print('Linkage quality of PPRL')\n",
    "prec, rec, f1 = link.evaluate(matches,db1,db2)\n",
    "print('Probable Privacy guarantees:', 'false positive rate of Bloom filters (larger better) - ', fpr)\n",
    "print('Provable Privacy guarantees:', 'Privacy budget (smaller better) - ', epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of common blocks: 51\n",
      "Number of matching pairs: 47\n"
     ]
    }
   ],
   "source": [
    "#Baseline: Macth and link from two datasets using non-privacy-preserving record linkage\n",
    "matches_npp = link.match_npp(blk_ind1,blk_ind2,db1,db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of common blocks: 51\n",
      "Number of matching pairs: 46\n"
     ]
    }
   ],
   "source": [
    "#Baseline2: Match and link Bloom filters from two datasets without DP guarantees\n",
    "matches_nodp = link.match(blk_ind1,blk_ind2,bf_dict1,bf_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linkage quality of non-PPRL\n",
      "Precision:  1.0\n",
      "Recall:  0.94\n",
      "F1 score:  0.9690721649484536\n",
      "Privacy guarantees: None\n"
     ]
    }
   ],
   "source": [
    "#Evaluate linkage quality of non-privacy-preserving record linkage baseline method\n",
    "print('Linkage quality of non-PPRL')\n",
    "prec_b1, rec_b1, f1_b1 = link.evaluate(matches_npp,db1,db2)\n",
    "print('Privacy guarantees:', 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linkage quality of PPRL without DP\n",
      "Precision:  1.0\n",
      "Recall:  0.92\n",
      "F1 score:  0.9583333333333334\n",
      "Probable Privacy guarantees: false positive rate of Bloom filters (larger better) -  0.9346272479320712\n",
      "Provable Privacy guarantees: None\n"
     ]
    }
   ],
   "source": [
    "#Evaluate linkage quality of privacy-preserving record linkage without Differential privacy guarantees\n",
    "print('Linkage quality of PPRL without DP')\n",
    "prec_b2, rec_b2, f1_b2 = link.evaluate(matches_nodp,db1,db2)\n",
    "print('Probable Privacy guarantees:', 'false positive rate of Bloom filters (larger better) - ', fpr)\n",
    "print('Provable Privacy guarantees:', 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
