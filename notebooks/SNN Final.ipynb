{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4763c18-0e9f-4601-a3e8-309764173be0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Final SNN Implementation (Paper-Reproduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82e5005a-c8a0-4dfb-8aea-4e632509e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import arff\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3766284-7826-4f2d-8d74-42a6843ec1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        uid1                                              text1       uid2  \\\n",
      "0  4983335-2  19-year-old RH dominant male presented to the ...  4983335-4   \n",
      "1  7933723-1  A 12-year-old girl visited the plastic surgery...  7933723-2   \n",
      "2  6963280-1  Case 1: A 27 years old female patient, living ...  6963280-4   \n",
      "3  7241960-1  Case 1 was a 6-year-old male, the first child ...  7241960-2   \n",
      "4  5308138-1  The patient is a 47-year-old, married male, wh...  5308138-4   \n",
      "\n",
      "                                               text2  label  \n",
      "0  25-year-old left hand dominant female presente...      1  \n",
      "1  A 38-year-old man with no underlying disease p...      1  \n",
      "2  Case 4: A 20 years old male patient resident o...      1  \n",
      "3  Case 2 was a 2.5-year-old female, second affec...      1  \n",
      "4  AC was a 55-year-old, divorced woman, living w...      1  \n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Step 1: Load data\n",
    "# ===========================\n",
    "\n",
    "\n",
    "train_df=pd.read_csv(\"your path to target_train.csv\")\n",
    "test_df=pd.read_csv(\"your path to target_tets.csv\")\n",
    "\n",
    "# sample_matching_df = pairwise_df[pairwise_df['label'] == 1].sample(n=50000, random_state=42)\n",
    "# sample_nonmatching_df = pairwise_df[pairwise_df['label'] == 0].sample(n=50000, random_state=42)\n",
    "# sample_df = pd.concat([sample_matching_df, sample_nonmatching_df]).reset_index(drop=True)\n",
    "\n",
    "# # Optionally, print sample_df to inspect\n",
    "# print(\"Sampled record pairs:\")\n",
    "# print(sample_df[['uid1', 'uid2', 'label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "556fbb9f-ceaf-4d41-a759-fdedd2b4f572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Generate embeddings only for train and test separately\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load pretrained BERT model and tokenizer\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "# Load ClinicalBERT\n",
    "tokenizer = BertTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "bert_model = TFBertModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "\n",
    "# Helper function for batched embedding generation\n",
    "def generate_embeddings_batched(texts, batch_size=32, max_length=512):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts.iloc[i:i+batch_size].tolist()\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"tf\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length  # âœ… Truncate to 512 tokens\n",
    "        )\n",
    "        outputs = bert_model(inputs[\"input_ids\"])\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "        all_embeddings.append(cls_embeddings.numpy())\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "# Encode and save embeddings\n",
    "x1_train = generate_embeddings_batched(train_df['text1'])\n",
    "x2_train = generate_embeddings_batched(train_df['text2'])\n",
    "y_train = train_df['label'].values.astype(np.float32)\n",
    "\n",
    "x1_test = generate_embeddings_batched(test_df['text1'])\n",
    "x2_test = generate_embeddings_batched(test_df['text2'])\n",
    "y_test = test_df['label'].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b239d7c-49ca-4302-a2e6-c55c2abd865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store cached files\n",
    "os.makedirs(\"clinicalbert\", exist_ok=True)\n",
    "# save the embeddings for later use\n",
    "np.save(\"clinicalbert/x1_train.npy\", x1_train)\n",
    "np.save(\"clinicalbert/x2_train.npy\", x2_train)\n",
    "np.save(\"clinicalbert/y_train.npy\", y_train)\n",
    "np.save(\"clinicalbert/x1_test.npy\", x1_test)\n",
    "np.save(\"clinicalbert/x2_test.npy\", x1_test)\n",
    "np.save(\"clinicalbert/y_test.npy\", y_test)\n",
    "\n",
    "# For the later experiments load the embeddings using following code\n",
    "# x1_train = np.load(\"clinicalbert/x1_train.npy\")\n",
    "# x2_train = np.load(\"clinicalbert/x2_train.npy\")\n",
    "# y_train = np.load(\"clinicalbert/y_train.npy\")\n",
    "# x1_test = np.load(\"clinicalbert/x1_test.npy\")\n",
    "# x2_test = np.load(\"clinicalbert/x2_test.npy\")\n",
    "# y_test = np.load(\"clinicalbert/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5281417a-ef2d-4689-ad31-a4fd78e787ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "272/272 [==============================] - 3s 10ms/step - loss: 1.8243 - val_loss: 1.7212\n",
      "Epoch 2/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.7219 - val_loss: 1.6998\n",
      "Epoch 3/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6893 - val_loss: 1.6928\n",
      "Epoch 4/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6902 - val_loss: 1.6778\n",
      "Epoch 5/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6882 - val_loss: 1.6726\n",
      "Epoch 6/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6834 - val_loss: 1.6702\n",
      "Epoch 7/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6849 - val_loss: 1.6904\n",
      "Epoch 8/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6797 - val_loss: 1.6666\n",
      "Epoch 9/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6742 - val_loss: 1.7225\n",
      "Epoch 10/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6780 - val_loss: 1.6894\n",
      "Epoch 11/30\n",
      "272/272 [==============================] - 4s 13ms/step - loss: 1.6814 - val_loss: 1.6626\n",
      "Epoch 12/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6724 - val_loss: 1.6852\n",
      "Epoch 13/30\n",
      "272/272 [==============================] - 3s 12ms/step - loss: 1.6670 - val_loss: 1.6749\n",
      "Epoch 14/30\n",
      "272/272 [==============================] - 4s 14ms/step - loss: 1.6819 - val_loss: 1.6938\n",
      "Epoch 15/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6749 - val_loss: 1.6788\n",
      "Epoch 16/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6667 - val_loss: 1.7230\n",
      "Epoch 17/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6750 - val_loss: 1.6734\n",
      "Epoch 18/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6664 - val_loss: 1.6705\n",
      "Epoch 19/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6822 - val_loss: 1.6799\n",
      "Epoch 20/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6750 - val_loss: 1.6991\n",
      "Epoch 21/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6672 - val_loss: 1.6684\n",
      "Epoch 22/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6667 - val_loss: 1.6696\n",
      "Epoch 23/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6695 - val_loss: 1.6692\n",
      "Epoch 24/30\n",
      "272/272 [==============================] - 3s 9ms/step - loss: 1.6705 - val_loss: 1.6689\n",
      "Epoch 25/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6790 - val_loss: 1.6562\n",
      "Epoch 26/30\n",
      "272/272 [==============================] - 2s 8ms/step - loss: 1.6726 - val_loss: 1.6599\n",
      "Epoch 27/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6658 - val_loss: 1.7270\n",
      "Epoch 28/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6756 - val_loss: 1.6656\n",
      "Epoch 29/30\n",
      "272/272 [==============================] - 2s 9ms/step - loss: 1.6593 - val_loss: 1.6633\n",
      "Epoch 30/30\n",
      "272/272 [==============================] - 4s 14ms/step - loss: 1.6639 - val_loss: 1.6609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f49f7668be0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================\n",
    "# Step 3: Build Siamese Autoencoder\n",
    "# ====================================\n",
    "def build_siamese_autoencoder(embedding_dim):\n",
    "    encoder_input = Input(shape=(embedding_dim,))\n",
    "    x = layers.Dense(50, activity_regularizer=regularizers.l1(0.01))(encoder_input)\n",
    "    x = layers.LeakyReLU(alpha=0.01)(x)\n",
    "    encoder_output = layers.Dense(embedding_dim, activation='relu')(x)\n",
    "    encoder = Model(encoder_input, encoder_output)\n",
    "\n",
    "    decoder_input = Input(shape=(embedding_dim,))\n",
    "    decoder_output = layers.Dense(embedding_dim, activation='sigmoid')(decoder_input)\n",
    "    decoder = Model(decoder_input, decoder_output)\n",
    "\n",
    "    input1 = Input(shape=(embedding_dim,))\n",
    "    input2 = Input(shape=(embedding_dim,))\n",
    "    encoded1 = encoder(input1)\n",
    "    encoded2 = encoder(input2)\n",
    "    recon1 = decoder(encoded1)\n",
    "    recon2 = decoder(encoded2)\n",
    "\n",
    "    merged_output = layers.Concatenate()([recon1, recon2])\n",
    "    model = Model(inputs=[input1, input2], outputs=merged_output)\n",
    "    return model, encoder\n",
    "\n",
    "def hybrid_classification_loss(margin=2.5, alpha=1.0):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        emb_dim = tf.shape(y_pred)[1] // 2\n",
    "        recon1 = y_pred[:, :emb_dim]\n",
    "        recon2 = y_pred[:, emb_dim:]\n",
    "        recon_loss = tf.reduce_mean(tf.square(recon1 - recon2), axis=1)\n",
    "        distances = tf.sqrt(tf.reduce_sum(tf.square(recon1 - recon2), axis=1))\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        contrastive_loss = y_true * tf.square(distances) + (1 - y_true) * tf.square(tf.maximum(margin - distances, 0))\n",
    "        return tf.reduce_mean(alpha * recon_loss + contrastive_loss)\n",
    "    return loss_fn\n",
    "embedding_dim = x1_train.shape[1]\n",
    "sa_model, encoder = build_siamese_autoencoder(embedding_dim)\n",
    "sa_model.compile(optimizer='adam', loss=hybrid_classification_loss(margin=2.5, alpha=1.0))\n",
    "sa_model.fit([x1_train, x2_train], y_train, epochs=30, batch_size=256, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4eb98e5-a528-4145-9aff-90e33687d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2415/2415 [==============================] - 4s 1ms/step\n",
      "2415/2415 [==============================] - 3s 1ms/step\n",
      "604/604 [==============================] - 1s 866us/step\n",
      "604/604 [==============================] - 1s 817us/step\n",
      "------ Siamese Autoencoder Evaluation ------\n",
      "Training Accuracy: 0.4961, F1 Score: 0.6460\n",
      "Test Accuracy: 0.4991, F1 Score: 0.6449\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Evaluate the Siamese Autoencoder (Threshold-based)\n",
    "# ==========================================================\n",
    "\n",
    "# Get reconstructions\n",
    "encoded1_train = encoder.predict(x1_train)\n",
    "encoded2_train = encoder.predict(x2_train)\n",
    "encoded1_test = encoder.predict(x1_test)\n",
    "encoded2_test = encoder.predict(x2_test)\n",
    "\n",
    "# Compute Euclidean distances\n",
    "train_distances = np.sqrt(np.sum((encoded1_train - encoded2_train)**2, axis=1))\n",
    "test_distances = np.sqrt(np.sum((encoded1_test - encoded2_test)**2, axis=1))\n",
    "\n",
    "# Use fixed threshold (e.g., 1.0) to classify matches\n",
    "threshold = 1.0\n",
    "train_pred = (train_distances < threshold).astype(int)\n",
    "test_pred = (test_distances < threshold).astype(int)\n",
    "\n",
    "# Accuracy & F1\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "train_f1 = f1_score(y_train, train_pred)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "\n",
    "print(\"------ Siamese Autoencoder Evaluation ------\")\n",
    "print(f\"Training Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98e34365-ce31-43bc-97fc-9af5afbdea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2415/2415 [==============================] - 2s 790us/step\n",
      "2415/2415 [==============================] - 2s 1ms/step\n",
      "604/604 [==============================] - 1s 954us/step\n",
      "604/604 [==============================] - 0s 791us/step\n",
      "Epoch 1/20\n",
      "272/272 [==============================] - 2s 5ms/step - loss: 0.5404 - accuracy: 0.7397 - val_loss: 0.4921 - val_accuracy: 0.7673\n",
      "Epoch 2/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4843 - accuracy: 0.7729 - val_loss: 0.4813 - val_accuracy: 0.7773\n",
      "Epoch 3/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4707 - accuracy: 0.7805 - val_loss: 0.4736 - val_accuracy: 0.7810\n",
      "Epoch 4/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4654 - accuracy: 0.7834 - val_loss: 0.4808 - val_accuracy: 0.7753\n",
      "Epoch 5/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4605 - accuracy: 0.7857 - val_loss: 0.4696 - val_accuracy: 0.7795\n",
      "Epoch 6/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4564 - accuracy: 0.7885 - val_loss: 0.4762 - val_accuracy: 0.7792\n",
      "Epoch 7/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.7902 - val_loss: 0.4696 - val_accuracy: 0.7790\n",
      "Epoch 8/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4494 - accuracy: 0.7930 - val_loss: 0.4668 - val_accuracy: 0.7827\n",
      "Epoch 9/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4452 - accuracy: 0.7968 - val_loss: 0.4664 - val_accuracy: 0.7845\n",
      "Epoch 10/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4408 - accuracy: 0.7982 - val_loss: 0.4665 - val_accuracy: 0.7870\n",
      "Epoch 11/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.4659 - val_accuracy: 0.7819\n",
      "Epoch 12/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4317 - accuracy: 0.8031 - val_loss: 0.4607 - val_accuracy: 0.7900\n",
      "Epoch 13/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4260 - accuracy: 0.8072 - val_loss: 0.4612 - val_accuracy: 0.7883\n",
      "Epoch 14/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4197 - accuracy: 0.8106 - val_loss: 0.4666 - val_accuracy: 0.7828\n",
      "Epoch 15/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4153 - accuracy: 0.8131 - val_loss: 0.4875 - val_accuracy: 0.7686\n",
      "Epoch 16/20\n",
      "272/272 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8185 - val_loss: 0.4648 - val_accuracy: 0.7869\n",
      "Epoch 17/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.4024 - accuracy: 0.8211 - val_loss: 0.4768 - val_accuracy: 0.7759\n",
      "Epoch 18/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.3962 - accuracy: 0.8248 - val_loss: 0.4727 - val_accuracy: 0.7825\n",
      "Epoch 19/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.3896 - accuracy: 0.8279 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
      "Epoch 20/20\n",
      "272/272 [==============================] - 1s 4ms/step - loss: 0.3829 - accuracy: 0.8329 - val_loss: 0.4719 - val_accuracy: 0.7828\n",
      "604/604 [==============================] - 1s 971us/step\n",
      "\n",
      "Classifier Evaluation:\n",
      "Accuracy: 0.7891\n",
      "F1 Score: 0.7776\n",
      "\n",
      "Detailed report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.84      0.80      9659\n",
      "         1.0       0.82      0.74      0.78      9658\n",
      "\n",
      "    accuracy                           0.79     19317\n",
      "   macro avg       0.79      0.79      0.79     19317\n",
      "weighted avg       0.79      0.79      0.79     19317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Step 4: Add Classification Head\n",
    "# ====================================\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "\n",
    "# Step 1: Get encoded outputs\n",
    "encoded1_train = encoder.predict(x1_train)\n",
    "encoded2_train = encoder.predict(x2_train)\n",
    "encoded1_test = encoder.predict(x1_test)\n",
    "encoded2_test = encoder.predict(x2_test)\n",
    "\n",
    "# Step 2: Compute absolute differences (Siamese-style)\n",
    "diff_train = np.abs(encoded1_train - encoded2_train)\n",
    "diff_test = np.abs(encoded1_test - encoded2_test)\n",
    "\n",
    "# Step 3: Build classification model\n",
    "input_diff = Input(shape=(diff_train.shape[1],))\n",
    "x = Dense(64, activation='relu')(input_diff)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "clf_model = Model(inputs=input_diff, outputs=output)\n",
    "\n",
    "clf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the classifier\n",
    "clf_model.fit(diff_train, y_train, epochs=20, batch_size=256, validation_split=0.1)\n",
    "\n",
    "# Step 5: Evaluate\n",
    "y_pred_prob = clf_model.predict(diff_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nClassifier Evaluation:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nDetailed report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1686d4d-f2e0-4e13-9b0c-60be04db3e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604/604 [==============================] - 0s 752us/step\n",
      "Classifier Accuracy: 0.7891494538489413\n",
      "Classifier F1 Score: 0.7776382595403177\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.84      0.80      9659\n",
      "         1.0       0.82      0.74      0.78      9658\n",
      "\n",
      "    accuracy                           0.79     19317\n",
      "   macro avg       0.79      0.79      0.79     19317\n",
      "weighted avg       0.79      0.79      0.79     19317\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piyumi/miniconda3/envs/myenv/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Step 5: Evaluation and Visualization\n",
    "# ====================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_prob = clf_model.predict(diff_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Classifier Accuracy:\", acc)\n",
    "print(\"Classifier F1 Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "# Save Model\n",
    "clf_model.save(\"snn_classifier_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52a9323d-7653-4afb-9508-e10505330c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution:\n",
      "1.0    38633\n",
      "0.0    38632\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train label distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eea73bd7-fc1e-418b-a5ed-36780c4c790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "218/218 [==============================] - 2s 5ms/step - loss: 0.8631 - accuracy: 0.7976 - val_loss: 0.4437 - val_accuracy: 0.8764\n",
      "Epoch 2/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8696 - val_loss: 0.3810 - val_accuracy: 0.8790\n",
      "Epoch 3/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3781 - accuracy: 0.8743 - val_loss: 0.3388 - val_accuracy: 0.8944\n",
      "Epoch 4/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3639 - accuracy: 0.8776 - val_loss: 0.3413 - val_accuracy: 0.8890\n",
      "Epoch 5/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3506 - accuracy: 0.8812 - val_loss: 0.3213 - val_accuracy: 0.8968\n",
      "Epoch 6/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3484 - accuracy: 0.8821 - val_loss: 0.3300 - val_accuracy: 0.8895\n",
      "Epoch 7/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3401 - accuracy: 0.8847 - val_loss: 0.3309 - val_accuracy: 0.8900\n",
      "Epoch 8/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3403 - accuracy: 0.8829 - val_loss: 0.3142 - val_accuracy: 0.8973\n",
      "Epoch 9/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.8813 - val_loss: 0.3372 - val_accuracy: 0.8826\n",
      "Epoch 10/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3375 - accuracy: 0.8820 - val_loss: 0.3150 - val_accuracy: 0.8978\n",
      "Epoch 11/30\n",
      "218/218 [==============================] - 1s 4ms/step - loss: 0.3379 - accuracy: 0.8829 - val_loss: 0.3126 - val_accuracy: 0.8971\n",
      "Epoch 12/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8828 - val_loss: 0.3355 - val_accuracy: 0.8884\n",
      "Epoch 13/30\n",
      "218/218 [==============================] - 1s 4ms/step - loss: 0.3415 - accuracy: 0.8805 - val_loss: 0.3231 - val_accuracy: 0.8932\n",
      "Epoch 14/30\n",
      "218/218 [==============================] - 1s 4ms/step - loss: 0.3450 - accuracy: 0.8791 - val_loss: 0.3352 - val_accuracy: 0.8839\n",
      "Epoch 15/30\n",
      "218/218 [==============================] - 1s 4ms/step - loss: 0.3440 - accuracy: 0.8795 - val_loss: 0.3172 - val_accuracy: 0.8947\n",
      "Epoch 16/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.8814 - val_loss: 0.3061 - val_accuracy: 0.8989\n",
      "Epoch 17/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3383 - accuracy: 0.8819 - val_loss: 0.3524 - val_accuracy: 0.8654\n",
      "Epoch 18/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3356 - accuracy: 0.8820 - val_loss: 0.3008 - val_accuracy: 0.8984\n",
      "Epoch 19/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3337 - accuracy: 0.8836 - val_loss: 0.3296 - val_accuracy: 0.8775\n",
      "Epoch 20/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3376 - accuracy: 0.8802 - val_loss: 0.3033 - val_accuracy: 0.8992\n",
      "Epoch 21/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3411 - accuracy: 0.8777 - val_loss: 0.3205 - val_accuracy: 0.8937\n",
      "Epoch 22/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3393 - accuracy: 0.8794 - val_loss: 0.3019 - val_accuracy: 0.8986\n",
      "Epoch 23/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3464 - accuracy: 0.8765 - val_loss: 0.3106 - val_accuracy: 0.8991\n",
      "Epoch 24/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3370 - accuracy: 0.8796 - val_loss: 0.3230 - val_accuracy: 0.8758\n",
      "Epoch 25/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8783 - val_loss: 0.3006 - val_accuracy: 0.8965\n",
      "Epoch 26/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3304 - accuracy: 0.8830 - val_loss: 0.3007 - val_accuracy: 0.8968\n",
      "Epoch 27/30\n",
      "218/218 [==============================] - 1s 5ms/step - loss: 0.3302 - accuracy: 0.8833 - val_loss: 0.3130 - val_accuracy: 0.8876\n",
      "Epoch 28/30\n",
      "218/218 [==============================] - 1s 4ms/step - loss: 0.3339 - accuracy: 0.8825 - val_loss: 0.3052 - val_accuracy: 0.8992\n",
      "Epoch 29/30\n",
      "218/218 [==============================] - 1s 4ms/step - loss: 0.3279 - accuracy: 0.8845 - val_loss: 0.2973 - val_accuracy: 0.8997\n",
      "Epoch 30/30\n",
      "218/218 [==============================] - 1s 4ms/step - loss: 0.3294 - accuracy: 0.8850 - val_loss: 0.2958 - val_accuracy: 0.8971\n",
      "483/483 [==============================] - 0s 828us/step\n",
      "\n",
      " Best Threshold (on pseudo-val set): 0.54 â€” Best F1 Score: 0.9061\n",
      "604/604 [==============================] - 0s 757us/step\n",
      "\n",
      " Final Evaluation on Test Set:\n",
      "Accuracy: 0.9043\n",
      "F1 Score: 0.9063\n",
      "\n",
      "Detailed Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.88      0.90      9659\n",
      "         1.0       0.89      0.93      0.91      9658\n",
      "\n",
      "    accuracy                           0.90     19317\n",
      "   macro avg       0.91      0.90      0.90     19317\n",
      "weighted avg       0.91      0.90      0.90     19317\n",
      "\n",
      " Test predictions saved to 'final_test_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# learn threshold from validation set\n",
    "# ========================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "# -------------------------------------------------------\n",
    "# Step 1: Create pseudo-validation set from training data\n",
    "# -------------------------------------------------------\n",
    "diff_train_full = np.abs(x1_train - x2_train)\n",
    "diff_test = np.abs(x1_test - x2_test)\n",
    "\n",
    "# Split 80% train / 20% val for threshold tuning\n",
    "diff_train_final, diff_val, y_train_final, y_val = train_test_split(\n",
    "    diff_train_full, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 2: Build and Train MLP Classifier\n",
    "# -------------------------------------------------------\n",
    "input_diff = Input(shape=(diff_train_final.shape[1],))\n",
    "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(input_diff)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "clf_model = Model(inputs=input_diff, outputs=output)\n",
    "\n",
    "clf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "clf_model.fit(diff_train_final, y_train_final, epochs=30, batch_size=256, validation_split=0.1)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 3: Tune threshold on the validation set\n",
    "# -------------------------------------------------------\n",
    "y_val_prob = clf_model.predict(diff_val).flatten()\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "    y_pred_val = (y_val_prob >= threshold).astype(int)\n",
    "    _, _, f1, _ = precision_recall_fscore_support(y_val, y_pred_val, average='binary')\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\n Best Threshold (on pseudo-val set): {best_threshold:.2f} â€” Best F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Step 4: Evaluate on the true test set using tuned threshold\n",
    "# -------------------------------------------------------\n",
    "y_test_prob = clf_model.predict(diff_test).flatten()\n",
    "y_test_pred = (y_test_prob >= best_threshold).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n Final Evaluation on Test Set:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Save predictions\n",
    "import pandas as pd\n",
    "pd.DataFrame({\n",
    "    \"True Label\": y_test,\n",
    "    \"Predicted Label\": y_test_pred,\n",
    "    \"Confidence\": y_test_prob\n",
    "}).to_csv(\"final_test_predictions.csv\", index=False)\n",
    "print(\" Test predictions saved to 'final_test_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff044826-998d-4a61-8780-e5147145e9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
